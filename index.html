<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ignacio  Alzugaray</title>
<meta name="description" content="Ignacio Alzugaray's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              Home
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item">
              <a class="nav-link" href="https://github.com/ialzugaray">
                Code
                <span class="sr-only">(current)</span>
              </a>
          </li>

          <li class="nav-item">
              <a class="nav-link" href="https://raw.githubusercontent.com/ialzugaray/cv/master/ignacio_alzugaray_cv.pdf">
                CV
                <span class="sr-only">(current)</span>
              </a>
          </li>

      <!-- Dark mode off
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
      -->
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Ignacio</span>  Alzugaray
    </h1>
     <p class="desc">PhD Candidate | Neuromorphic sensors & Computer Vision | <a href="https://ethz.ch/">ETH Zurich</a>, <a href="https://v4rl.ethz.ch/">Vision for Robotics Lab</a>.</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/bio-photo.png">
      
      
        <div class="address">
          
        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am currently pursuing my PhD in Computer Vision at the <a href="https://ethz.ch/">ETH Zurich</a>, <a href="https://v4rl.ethz.ch/">Vision for Robotics Lab</a> advised by <a href="http://www.margaritachli.com/"> Margarita Chli</a>.</p>

<p>My research interest is in Computer Vision and I am currently investing the use of neuromorphic event cameras in the visual SLAM problem.  While event cameras are really fast and efficient, their output is asynchronous and sparse in constrast to the images acquired by traditional cameras. My doctoral studies are focused on developing novel Computer Vision algorithms that can fully exploit the characteristics of this new sensing modality.</p>

<p>Take a look at my lastest <a href="/publications">publications</a>!</p>


    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Jun 9, 2021</th>
          <td>
            
              I have been invited to give a talk at the <a href="https://tub-rip.github.io/eventvision2021/">CVPR 2021 Workshop on Event-based Vision</a>. The <a href="https://youtu.be/mzwWI3DjMXI">video</a> and <a href="https://tub-rip.github.io/eventvision2021/slides/CVPRW21_Alzugaray_Chli_Lab.pdf">slides</a> are already available.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 24, 2021</th>
          <td>
            
              We are publicly releasing the <a href="https://github.com/ialzugaray/haste">code</a> for <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0744.html">HASTE</a>, our latest publication on feature tracking with event cameras .

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 15, 2020</th>
          <td>
            
              I will join <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a> team for a short internship in 2021 Q4.


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 9, 2020</th>
          <td>
            
              We are presenting our latest work on efficient feature tracking for event cameras <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0744.html">HASTE</a> at BMVC.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">BMVC</abbr>
    
  
  </div>

  <div id="bmvc" class="col-sm-8">
    
      <div class="title">HASTE: multi-Hypothesis Asynchronous Speeded-up Tracking of Events</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Alzugaray, Ignacio</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Chli, Margarita
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In British Machine Vision Virtual Conference (BMVC)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0744.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/439297/1/BMVC2020_HASTE_0744.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Feature tracking using event cameras has experienced significant progress lately, with methods achieving comparable performance to feature trackers using traditional frame-based cameras, even outperforming them on certain challenging scenarios. Most of the event-based trackers, however, still operate on intermediate, frame-like representations generated from accumulated events, on which traditional frame-based techniques can be adopted. Attempting to harness the sparsity and asynchronicity of the event stream, other approaches have emerged to process each event individually, but they lack both in accuracy and efficiency in comparison to the event-based, frame-like alternatives. Aiming to address this shortcoming of asynchronous approaches, in this paper, we propose an asynchronous patch-feature tracker that relies solely on events and processes each event individually as soon as it gets generated. We report significant improvements in tracking quality over the state of the art in publicly available datasets, while performing an order of magnitude more efficiently than similar asynchronous tracking approaches.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">3DV</abbr>
    
  
  </div>

  <div id="8491018" class="col-sm-8">
    
      <div class="title">ACE: An Efficient Asynchronous Corner Tracker for Event Cameras</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Alzugaray, Ignacio</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Chli, Margarita
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on 3D Vision (3DV)</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/8491018" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/308013/3DV2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The emergence of bio-inspired event cameras has opened up new exciting possibilities in high-frequency tracking, overcoming some of the limitations of traditional frame-based vision (e.g. motion blur during high-speed motions or saturation in scenes with high dynamic range). As a result, research has been focusing on the processing of their unusual output: an asynchronous stream of events. With the majority of existing techniques discretizing the event-stream into frame-like representations, we are yet to harness the true power of these cameras. In this paper, we propose the ACE tracker: a purely asynchronous framework to track corner-event features. Evaluation on benchmarking datasets reveals significant improvements in accuracy and computational efficiency in comparison to state-of-the-art event-based trackers. ACE achieves robust performance even in challenging scenarios, where traditional frame-based vision algorithms fail.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">RA-L / IROS</abbr>
    
  
  </div>

  <div id="8392795" class="col-sm-8">
    
      <div class="title">Asynchronous Corner Detection and Tracking for Event Cameras in Real Time</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Alzugaray, Ignacio</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Chli, Margarita
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Robotics and Automation Letters</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/8392795" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/277131/RAL2018-camera-ready.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The recent emergence of bioinspired event cameras has opened up exciting new possibilities in high-frequency tracking, bringing robustness to common problems in traditional vision, such as lighting changes and motion blur. In order to leverage these attractive attributes of the event cameras, research has been focusing on understanding how to process their unusual output: an asynchronous stream of events. With the majority of existing techniques discretizing the event-stream essentially forming frames of events grouped according to their timestamp, we are still to exploit the power of these cameras. In this spirit, this letter proposes a new, purely event-based corner detector, and a novel corner tracker, demonstrating that it is possible to detect corners and track them directly on the event stream in real time. Evaluation on benchmarking datasets reveals a significant boost in the number of detected corners and the repeatability of such detections over the state of the art even in challenging scenarios with the proposed approach while enabling more than a 4Ã— speed-up when compared to the most efficient algorithm in the literature. The proposed pipeline detects and tracks corners at a rate of more than 7.5 million events per second, promising great impact in high-speed applications.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICRA</abbr>
    
  
  </div>

  <div id="7989319" class="col-sm-8">
    
      <div class="title">Short-term UAV path-planning with monocular-inertial SLAM in the loop</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Alzugaray, Ignacio</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Teixeira, Lucas,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Chli, Margarita
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/7989319" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/235995.1/eth-50627-01.pdf?sequence=1" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Small Unmanned Aerial Vehicles (UAVs) are some of the most promising robotic platforms in a variety of applications due to their high mobility. Their restricted computational and payload capabilities, however, translate into significant challenges in automating their navigation. With Simultaneous Localization And Mapping (SLAM) systems recently demonstrated to be employable onboard UAVs, the focus fall on path-planning on the quest of achieving autonomous navigation. With the vast body of path-planning literature often assuming perfect maps or maps known a priori, the biggest challenge lies in dealing with the robustness and accuracy limitations of onboard SLAM in real missions. In this spirit, this paper proposes a path-planning algorithm designed to work in the loop of the SLAM estimation of a monocular-inertial system. This point-to-point planner is demonstrated to navigate in an unknown environment using the incrementally generated SLAM map, while dictating the navigation strategy for preferable acquisition of sensor data for better estimations within SLAM. A thorough evaluation testbed of both simulated and real data is presented, demonstrating the robustness of the proposed pipeline against the state-of-the-art and its dramatically lower computational complexity, revealing its suitability to UAV navigation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%61%6C%7A%75%67%61%72%61%79.%69%67%6E@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=IZAZcr4AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/ialzugaray" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/ialzugaray" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/alzugarayign" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>










      </div>
      <div class="contact-note">Best way to reach me is via <a href="mailto:alzugaray.ign@gmail.com"">email</a></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Ignacio  Alzugaray.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    
    Last updated: June 10, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
